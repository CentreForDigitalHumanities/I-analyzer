'''
Module contains the base classes from which corpora can derive; 
'''

import bs4
from datetime import datetime, timedelta

import logging; logger = logging.getLogger(__name__)
from .. import extract


class Corpus(object):
    '''
    Subclasses of this class define corpora by specifying:
    
    - How to obtain its source files.
    - What attributes its documents have.
    - How to extract said attributes from the source files.
    - What each attribute looks like, so that a search form can be constructed.    
    '''

    @property
    def DATA(self):
        '''
        Path to source data directory.
        '''
        raise NotImplementedError()



    @property
    def ES_INDEX(self):
        '''
        ElasticSearch index name.
        '''
        raise NotImplementedError()



    @property
    def ES_DOCTYPE(self):
        '''
        ElasticSearch document type name.
        '''
        raise NotImplementedError()



    @property
    def MIN_DATE(self):
        '''
        Minimum timestamp for data files.
        '''
        raise NotImplementedError()



    @property
    def MAX_DATE(self):
        '''
        Maximum timestamp for data files.
        '''
        raise NotImplementedError()



    @property
    def fields(self):
        '''
        Each corpus should implement a list of fields, that is, instances of
        the `Field` class, containing information about each attribute.
        '''
        raise NotImplementedError()



    def json(self):
        '''
        Corpora should be able to produce JSON, so that the fields they define
        can be used by other codebases, while retaining the Python class as the
        single source of truth.
        '''
        #TODO
        raise NotImplementedError()
        
        

    def sources(self, start=datetime.min, end=datetime.max):
        '''
        Obtain source files for the corpus, relevant to the given timespan.
        
        Specifically, returns an iterator of tuples that each contain a string
        filename and a dictionary of associated metadata. The latter is usually
        empty or contains only a timestamp; but any data that is to be
        extracted without reading the file itself can be specified there.
        '''
        raise NotImplementedError()



    def source2dicts(self, filename, metadata={}):
        '''
        Generate an iterator of document dictionaries from a given source file.
        
        The dictionaries are created from this corpus' `Field`s.
        '''
        raise NotImplementedError()



    def documents(self, sources=None):
        '''
        Generate an iterator of document dictionaries directly from the source
        files. The source files are generated by self.sources(); however, if
        `sources` is specified, those source/metadata tuples are used instead.
        '''
        sources = sources or self.sources()

        return (document
            for filename, metadata in sources
                for document in self.source2dicts(
                    filename=filename,
                    metadata=metadata,
                )
        )



class XMLCorpus(Corpus):
    '''
    An XMLCorpus is any corpus that extracts its data from XML sources.
    '''
    
    @property
    def xml_tag_toplevel(self):
        '''
        The top-level tag in the XML source documents.
        '''
        raise NotImplementedError()



    @property
    def xml_tag_entry(self):
        '''
        The XML tag that corresponds to a single document entry.
        '''
        raise NotImplementedError()


    
    def source2dicts(self, xmlfile, metadata={}):
        '''
        Generate a document dictionaries from a given XML file. Default
        implementation for standard XML layouts; may be subclassed.
        '''
        
        fields = self.fields

        # Loading XML
        logger.info('Reading XML file {} ...'.format(xmlfile))
        with open(xmlfile, 'rb') as f:
            data = f.read()
            
        # Parsing XML
        soup = bs4.BeautifulSoup(data, 'lxml-xml')

        logger.info('Loaded {} into memory ...'.format(xmlfile))

        # Extract fields from soup
        tag0 = self.xml_tag_toplevel
        tag  = self.xml_tag_entry
        soup_bowl = soup.find(tag0) if tag0 else soup
        if soup_bowl:
            for soup_spoon in soup_bowl.find_all(tag):
                extractor = field.extractor(metadata)
                yield {
                    field.name : extractor(soup_bowl, soup_spoon, metadata)
                    for field in fields
                        if field.indexed
                }
        else:
            logger.warning('Top-level tag not found in `{}`'.format(xmlfile))



# Fields ######################################################################


class Field(object):
    '''
    Fields hold data about the name of their columns in CSV files, how the
    corresponding content is to be extracted from BeautifulSoup, how they are
    described in user interfaces, what ElasticSearch filters are associated
    with them, how they are mapped in the index, etcetera.
    
    In short, this is how all things related to the informational structure of
    each particular corpus is stored.
    '''


    def __init__(self,
            name=None, # 
            description=None,
            indexed=True,
            hidden=False,
            mapping={ 'type' : 'text' },
            filter_=None,
            extractor=[],
            **kwargs
            ):

        self.name = name
        self.description = description
        self.filter_ = filter_
        self.mapping = mapping
        self.indexed = indexed
        self.hidden = not indexed or hidden
        self.extractors = extractor


    def extractor(self, metadata):
        '''
        Select the appropriate function to extract the data for this field from
        the source file, based on the provided metadata about said source file.
        '''

        for is_appropriate, extractor in self.extractors:
            if is_appropriate is None or is_appropriate(metadata):
                return extractor
        return extract.const(None)


    @property
    def filterclass(self):
        return self.filter_ and self.filter_.__class__.__name__




# Helper functions ############################################################

def until(year):
    '''
    Returns a predicate to determine from metadata whether its 'date' field
    represents a date before or on the given year.
    '''
    def f(metadata):
        date = metadata.get('date')
        return date and date.year <= year
    return f



def after(year):
    '''
    Returns a predicate to determine from metadata whether its 'date' field
    represents a date after the given year.
    '''
    def f(metadata):
        date = metadata.get('date')
        return date and date.year > year
    return f



def default(metadata):
    '''
    Predicate that is true on any input.
    '''
    return True
