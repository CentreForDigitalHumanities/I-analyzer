'''
Module contains the base classes from which corpora can derive; 
'''

import bs4
from datetime import datetime, timedelta

import logging; logger = logging.getLogger(__name__)
from .. import extract


class Corpus(object):
    '''
    Subclasses of this class define corpora by specifying:
    
    - How to obtain its source files.
    - What attributes its documents have.
    - How to extract said attributes from the source files.
    - What each attribute looks like, so that a search form can be constructed.    
    '''

       
    @property
    def data_directory(self):
        '''
        Path to source data directory.
        '''
        raise NotImplementedError()



    @property
    def min_date(self):
        '''
        Minimum timestamp for data files.
        '''
        raise NotImplementedError()



    @property
    def max_date(self):
        '''
        Maximum timestamp for data files.
        '''
        raise NotImplementedError()



    @property
    def es_index(self):
        '''
        ElasticSearch index name.
        '''
        raise NotImplementedError()



    @property
    def es_doctype(self):
        '''
        ElasticSearch document type name.
        '''
        raise NotImplementedError()
        
        
        
    @property
    def es_settings(self):
        '''
        Dictionary containing ElasticSearch settings for the corpus' index.
        '''
        raise NotImplementedError()



    @property
    def fields(self):
        '''
        Each corpus should implement a list of fields, that is, instances of
        the `Field` class, containing information about each attribute.
        '''
        raise NotImplementedError()



    def es_mapping(self):
        '''
        Create the ElasticSearch mapping for the fields of this corpus. May be
        passed to the body of an ElasticSearch index creation request.
        '''
        result = {
            'mappings' : {
                self.es_doctype : {
                    'properties': {
                        field.name : field.mapping
                        for field in self.fields
                        if field.mapping and field.indexed
                    }
                }
            }
        }
        
        if self.es_settings:
            result['settings'] = self.es_settings

        return result



    def json(self):
        '''
        Corpora should be able to produce JSON, so that the fields they define
        can be used by other codebases, while retaining the Python class as the
        single source of truth.
        '''
        #TODO
        raise NotImplementedError()
        
        

    def sources(self, start=datetime.min, end=datetime.max):
        '''
        Obtain source files for the corpus, relevant to the given timespan.
        
        Specifically, returns an iterator of tuples that each contain a string
        filename and a dictionary of associated metadata. The latter is usually
        empty or contains only a timestamp; but any data that is to be
        extracted without reading the file itself can be specified there.
        '''
        raise NotImplementedError()



    def source2dicts(self, filename, metadata={}):
        '''
        Generate an iterator of document dictionaries from a given source file.
        
        The dictionaries are created from this corpus' `Field`s.
        '''
        raise NotImplementedError()



    def documents(self, sources=None):
        '''
        Generate an iterator of document dictionaries directly from the source
        files. The source files are generated by self.sources(); however, if
        `sources` is specified, those source/metadata tuples are used instead.
        '''
        sources = sources or self.sources()

        return (document
            for filename, metadata in sources
                for document in self.source2dicts(
                    filename=filename,
                    metadata=metadata,
                )
        )



class XMLCorpus(Corpus):
    '''
    An XMLCorpus is any corpus that extracts its data from XML sources.
    '''
    
    @property
    def xml_tag_toplevel(self):
        '''
        The top-level tag in the XML source documents.
        '''
        raise NotImplementedError()



    @property
    def xml_tag_entry(self):
        '''
        The XML tag that corresponds to a single document entry.
        '''
        raise NotImplementedError()


    
    def source2dicts(self, xmlfile, metadata={}):
        '''
        Generate a document dictionaries from a given XML file. Default
        implementation for standard XML layouts; may be subclassed.
        '''
        
        fields = self.fields

        # Loading XML
        logger.info('Reading XML file {} ...'.format(xmlfile))
        with open(xmlfile, 'rb') as f:
            data = f.read()
            
        # Parsing XML
        soup = bs4.BeautifulSoup(data, 'lxml-xml')

        logger.info('Loaded {} into memory ...'.format(xmlfile))

        # Extract fields from soup
        tag0 = self.xml_tag_toplevel
        tag  = self.xml_tag_entry
        bowl = soup.find(tag0) if tag0 else soup
        if bowl:
            for spoon in bowl.find_all(tag): # Note that this is non-recursive: will only find children

                if not isinstance(field.extractor, (
                        extract.XML,
                        extract.Metadata,
                        extract.Constant
                    )):
                    raise RuntimeError("Specified extractor method cannot be used with an XML corpus")

                yield {
                    field.name : field.extractor.apply(
                        soup_top=bowl,
                        soup_entry=spoon,
                        metadata=metadata
                    ) for field in fields if field.indexed
                }
        else:
            logger.warning('Top-level tag not found in `{}`'.format(xmlfile))



# Fields ######################################################################


class Field(object):
    '''
    Fields hold data about the name of their columns in CSV files, how the
    corresponding content is to be extracted from the source, how they are
    described in user interfaces, what ElasticSearch filters are associated
    with them, how they are mapped in the index, etcetera.
    
    In short, this is how all things related to the informational structure of
    each particular corpus is stored.
    '''


    def __init__(self,
            name=None,
            description=None,
            indexed=True,
            hidden=False,
            es_mapping={ 'type' : 'text' },
            filter_=None,
            extractor=extract.Constant(None),
            **kwargs
            ):

        self.name = name
        self.description = description
        self.filter_ = filter_
        self.es_mapping = es_mapping
        self.indexed = indexed
        self.hidden = not indexed or hidden
        self.extractor = extractor


    @property
    def filterclass(self):
        '''
        Return the name of the filter associated with this Field, or None if
        there is no such filter.
        
        TODO: Used to automatically create a form in Jinja2 template. Clearly,
        this can be done in a better way. (WTForms)
        '''
        return self.filter_ and self.filter_.__class__.__name__




# Helper functions ############################################################

def string_contains(target):
    '''
    Return a predicate that performs a case-insensitive search for the target
    string and returns whether it was found.
    '''
    def f(string):
        return bool(target.lower() in string.lower() if string else False)
    return f



def until(year):
    '''
    Returns a predicate to determine from metadata whether its 'date' field
    represents a date before or on the given year.
    '''
    def f(metadata):
        date = metadata.get('date')
        return date and date.year <= year
    return f



def after(year):
    '''
    Returns a predicate to determine from metadata whether its 'date' field
    represents a date after the given year.
    '''
    def f(metadata):
        date = metadata.get('date')
        return date and date.year > year
    return f
