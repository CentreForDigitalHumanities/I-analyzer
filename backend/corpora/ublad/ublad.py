from datetime import datetime
import os
from os.path import join, splitext
import locale
import logging

from django.conf import settings
from addcorpus.python_corpora.corpus import HTMLCorpusDefinition, FieldDefinition
from ianalyzer_readers.extract import XML
from ianalyzer_readers.xml_tag import Tag
from addcorpus.es_mappings import *
from addcorpus.python_corpora.filters import DateFilter
from addcorpus.es_settings import es_settings


def transform_content(soup):
    """
    Transforms the text contents of a page node (soup) into a string consisting
    of blocks of text, foregoing the column structure of the OCR'ed material.
    """
    page_text = ""
    for child in soup.children:
        if isinstance(child, Tag) and 'ocr_carea' in child.get('class', []):
            paragraph_text = ""
            paragraph_list = child.get_text().split('\n')
            for item in paragraph_list[1:]:
                if not item:
                    pass
                elif item.endswith('-'):
                    paragraph_text += item.strip('-')
                else:
                    paragraph_text += item + ' '
            if paragraph_text:
                page_text += paragraph_text + '\n\n'
    return page_text

def transform_date(date_string):
    try:
        locale.setlocale(locale.LC_ALL, 'nl_NL.UTF-8')
        date = datetime.strptime(date_string, '%d %B %Y').strftime('%Y-%m-%d')
        locale.setlocale(locale.LC_ALL, '')
        return date
    except ValueError:
        logger.error("Unable to get date from {}".format(date_string))
        return None


logger = logging.getLogger('indexing')

class UBlad(HTMLCorpusDefinition):
    title = 'U-Blad'
    description = 'The print editions of the Utrecht University paper from 1969 until 2010.'
    description_page = 'ublad.md'
    min_date = datetime(year=1969, month=1, day=1)
    max_date = datetime(year=2010, month=12, day=31)

    data_directory = settings.UBLAD_DATA
    es_index = getattr(settings, 'UBLAD_ES_INDEX', 'ublad')
    image = 'ublad.jpg'
    scan_image_type = 'image/jpeg'
    allow_image_download = True

    document_context = {
        'context_fields': ['volume_id'],
        'sort_field': 'sequence',
        'sort_direction': 'asc',
        'context_display_name': 'volume'
    }

    languages = ['nl']
    category = 'periodical'

    @property
    def es_settings(self):
        return es_settings(self.languages[:1], stopword_analysis=True, stemming_analysis=True)

    def sources(self, **kwargs):
        for directory, _, filenames in os.walk(self.data_directory):
            _body, tail = os.path.split(directory)
            if '.snapshot' in _:
                _.remove('.snapshot')
                continue
            for filename in filenames:
                if filename != '.DS_Store':
                    full_path = join(directory, filename)
                    yield full_path, {'filename': filename}


    fields = [
        FieldDefinition(
            name = 'content',
            display_name='Content',
            display_type='text_content',
            description='Text content of the page, generated by OCR',
            results_overview=True,
            csv_core=True,
            search_field_core=True,
            visualizations=['ngram', 'wordcloud'],
            es_mapping = main_content_mapping(True, True, True, 'nl'),
            extractor=XML(
                Tag('div', attrs={'class': 'ocr_page'}),
                extract_soup_func=transform_content,
            )
        ),
        FieldDefinition(
            name='pagenum',
            display_name='Page number',
            description='Page number',
            csv_core=True,
            es_mapping = int_mapping(),
            extractor = XML(
                Tag('meta', attrs={'name': 'pagenum'}),
                attribute='content'
            )
        ),
        FieldDefinition(
            name='journal_title',
            display_name='Publication Title',
            description='Title of the publication',
            extractor=XML(
                Tag('meta', attrs={'name': 'journal_title'}),
                attribute='content',
            ),
        ),
        FieldDefinition(
            name='volume_id',
            display_name='Volume ID',
            description='Unique identifier for this volume',
            hidden=True,
            es_mapping=keyword_mapping(),
            extractor=XML(
                Tag('meta', attrs={'name': 'identifier_ocn'}),
                attribute='content',
            ),
        ),
        FieldDefinition(
            name='id',
            display_name='Page ID',
            description='Unique identifier for this page',
            hidden=True,
            extractor=XML(
                Tag('meta', attrs={'name': 'identifier_indexid'}),
                attribute='content',
            )
        ),
        FieldDefinition(
            name='edition',
            display_name='Edition',
            description='The number of the edition in this volume. Every year starts at 1.',
            sortable=True,
            es_mapping = keyword_mapping(),
            extractor=XML(
                Tag('meta', attrs={'name': 'aflevering'}),
                attribute='content',
            )
        ),
        FieldDefinition(
            name='volume',
            display_name='Volume',
            sortable=True,
            results_overview=True,
            csv_core=True,
            description='The volume number of this publication. There is one volume per year.',
            es_mapping=keyword_mapping(),
            extractor=XML(
                Tag('meta', attrs={'name': 'yearstring'}),
                attribute='content',
            ),
        ),
        FieldDefinition(
            name='date',
            display_name='Date',
            description='The publication date of this edition',
            es_mapping={'type': 'date', 'format': 'yyyy-MM-dd'},
            visualizations=['resultscount', 'termfrequency'],
            sortable=True,
            results_overview=True,
            search_filter=DateFilter(
                min_date,
                max_date,
                description=(
                    'Accept only articles with publication date in this range.'
                )
            ),
            extractor=XML(
                Tag('meta', attrs={'name': 'datestring'}),
                attribute='content',
                transform=transform_date,

            ),
        ),
        FieldDefinition(
            name='repo_url',
            display_name='Repository URL',
            description='URL to the dSPACE repository entry of this volume',
            es_mapping=keyword_mapping(),
            display_type='url',
            searchable=False,
            extractor=XML(
                Tag('meta', attrs={'name': 'link_repository'}),
                attribute='content',
            ),
        ),
        FieldDefinition(
            name='reader_url',
            display_name='Reader URL',
            description='URL to the UB reader view of this page',
            es_mapping=keyword_mapping(),
            display_type='url',
            searchable=False,
            extractor=XML(
                Tag('meta', attrs={'name': 'link_objects_image'}),
                attribute='content',
            ),
        ),
        FieldDefinition(
            name='jpg_url',
            display_name='Image URL',
            description='URL to the jpg file of this page',
            es_mapping=keyword_mapping(),
            display_type='url',
            searchable=False,
            extractor=XML(
                Tag('meta', attrs={'name': 'link_objects_jpg'}),
                attribute='content',
            ),
        ),
        FieldDefinition(
            name='worldcat_url',
            display_name='Worldcat URL',
            description='URL to the Worldcat entry of this volume',
            es_mapping=keyword_mapping(),
            display_type='url',
            searchable=False,
            extractor=XML(
                Tag('meta', attrs={'name': 'link_worldcat'}),
                attribute='content',
            ),
        )
    ]

    def request_media(self, document, corpus_name):
        image_list = [document['fieldValues']['jpg_url']]
        return {'media': image_list}
